{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 많은 머신러닝 문제의 경우 훈련 샘플 각각이 수천 심지어 수백만 개의 특성을 가지고 있습니다. 이는 훈련을 느리게 할 뿐만 아니라, 앞으로 보게 되겠지만 좋은 솔루션을 찾기 어렵게 만듭니다. 이런 문제를 종종 차원의 저주라고 한다.\n",
    "\n",
    "\n",
    "2. 차원을 축소 시키면 일부 정보가 유실됩니다. 그래서 훈련 속도가 빨라질 수는 있지만 시스템의 성능이 조금 나빠질 수 있다. 또한 작업 파이프라인이 좀 더 복잡하게 되고 유지관리가 어려워진다. 그러므로 차원 축소를 고려하기 전에 훈련이 느린지 먼저 원본 데이터로 시스템을 훈련시켜 봐야 한다. 그러나 어떤 경우에는 훈련 데이터의 차원을 축소시키면 잡음이나 불필요한 세부사항을 걸러내므로 성능을 높일 수 있다. (일반적으로는 훈련 속도만 빨라진다)\n",
    "\n",
    "\n",
    "3. 훈련 속도를 높이는 것 외에 차원 축소는 데이터 시각화에도 아주 유용합니다. 차원 수를 둘로 줄이면 고차원 훈련 세트를 하나의 그래프로 그릴 수 있고 군집 같은 시각적인 패턴을 감지해 중요한 통찰을 얻는 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 차원의 저주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고차원 공간에서는 많은 것이 상당히 다르게 작동합니다. 고차원의 데이터 셋이 매우 희박한 상태일 수 있다. 즉, 대부분의 훈련 데이터가 서로 멀리 떨어져 있다. 물론 이는 새로운 샘플도 훈련 샘플과 멀리 떨어져 있을 가능성이 높다는 뜻이다. 이 경우 예측을 위해 훨씬 많은 외삽을 해야 하기 때문에 저차원보다 예측이 더 불안정하다. 간단히 말해 훈련 세트의 차원의 클수록 과대적합의 위험이 커집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 차원 축소를 위한 접근 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구체적인 차원을 감소하는 두 가지 주요한 접근법인 투영과 매니폴드 학습을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 투영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대부분의 실전 문제는 훈련 샘플이 모든 차원에 걸쳐 균일하게 퍼져 있지 않다. 많은 특성의 변화가 거의 없는 반면, 다른 특성은 서로 강하게 연관되어 있다. 결과적으로 모든 훈련 샘플이 사실 고차원 공간 안의 저차원 부분 공간에 놓여 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 훈련 샘플이 거의 평면 형태로 놓여있습니다. 이것이 고차원 공간에 있는 저차원 부분 공간이다. 여기서 모든 훈련 샘플을 이 부분 공간에 수직으로(즉, 샘플과 평면 사이의 가장 짧은 직선을 따라) 투영하면 2D 데이터셋을 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 매니폴드 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스위스롤은 2D 매니폴딍 한 예다. 간단히 말해 2D 매니 폴드는 고차원 공간에서 휘어지거나 뒤틀린 2D 모양이다. 더 일반적으로 d차원 매니폴드는 국부적으로 d 차원 초평면으로 보일 수 있는 n 차원 공간의 일부이다. (d < n). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 많은 차원 축소 알고리즘이 훈련 샘플이 놓여 있는 매니폴드를 모델링하는 식으로 작동한다. 이를 매니폴드 학습이라 한다. 이는 대부분 실제 고차원 데이터셋이 낮은 저차원 매니폴드에 가깝게 놓여 있다는 매니폴드 가정 또는 매니폴드 가설에 근거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 데이터셋으로 생각해보겠습니다. 전체 손글씨 숫자 이미지는 어느 정도 비슷한 면이 있습니다. 선으로 연결되어 있고 경계는 흰색이고 어느 정도 중앙에 있습니다. 무작위로 생성된 이미지라면 그 중 아주 적은 일부만 손글씨 숫자처럼 보일 것이다. 다시 말해 숫자 이미지를 만들 때 가능한 자유도는 아무 이미지나 생성할 때 자유도보다 훨씬 낮다. 이런 제약은 데이터셋을 저차원 매니폴드로 압축할 수 있도록 도와준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그러나 이런 가정이 항상 유효하지는 않다. 두 번쨰 행의 경우에는 결정 경계가 x1 = 5에 놓여 있다. 이 결정 경계는 3D 공간에서는 매우 단순합니다. 하지만 펼쳐진 매니폴드에서는 결정 경계가 복잡해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 요약하면 모델을 훈련시키기 전에 훈련 세트 차원을 감소시키면 훈련 속도는 빨라지지만 항상 더 낫거나 간단한 솔루션이 되는 것은 아니다. 이는 전적으로 데이터셋에 달려 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PCA(투영)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주성분 분석은 가장 인기 있는 차원 축소 알고리즘입니다. 먼저 데이터에 가장 가까운 초평면을 정의한다음 데이터를 이 평면에 투영한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 분산 보존"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 저차원의 초평면에 훈련 세트를 투영하기 전에 먼저 올바른 초평면을 선택해야 한다. 다른 방향으로 투영하는 것보다 분산이 최대로 보존되는 축을 선택하는 것이 정보가 가장 적게 손실되므로 합리적인 것 같다. 이 선택을 다른 방식으로 선택하면 원본 데이터셋과 투영된 것 사이의 평균 제곱 거리를 최소화하는 축이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 주성분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA는 훈련 세트에서 분산이 최대인 축을 찾는다. 또한 첫 번째 축에 직교하고 남은 분산을 최대한 보존하는 두 번째 축을 찾습니다. 이 2D 예제에서는 선택의 여지가 없다.\n",
    "\n",
    "- i번째 축을 정의하는 단위 벡터를 i번째 주성분이라고 부른다.\n",
    "\n",
    "- 훈련 세트의 주성분을 찾는 방법은 SVD라는 표준 행렬 분해 기술이 있어서 훈련 세트 행렬 X를 세 개 내적인 U SIGMA Vt 로 분해할 수 있다. 여기에서 찾고자 하는 모든 주성분이 V에 담겨 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_train.reshape(-1, 784)\n",
    "Y_train = y_train.reshape(-1, 1)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_index = np.random.choice(len(X_train), 5000)\n",
    "X = X_train[rnd_index,:]\n",
    "y = Y_train[rnd_index,:]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA는 데이터 셋 평균이 0 이라 가정합니다. 앞으로 사이킷런의 PCA 클래스는 이 작업을 대신 수행한다. 그러나 PCA를 직접 구현하거나 다른 라이브러리를 사용한다면 먼저 데이터를 원점에 맞추어주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. d 차원 투영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주성분을 모두 추출했다면 처음 d 개의 주성분으로 정의한 초평면에 투영하여 데이터셋의 차원을 d 차원으로 축소시킬 수 있다. 이 초평면은 분산을 가능한 최대로 보존하는 투영이다. 초평면에 훈련 세트를 투영하기 위해서는 행렬 X와 처음 d 개의 주성분을 담은 행렬 Wd를 점곱하면 됩니다. (즉, V의 첫 열로 구성된)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xd-proj = X.dot(Wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 2개의 주성분으로 정의된 평면에 훈련 세트를 투영한다.\n",
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 사이킷런 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 사이킷런은 \n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA 변환기를 데이터셋에 학습하고 나면 components_ 변수를 사용해 주성분을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.04592535e-18,  1.44271074e-18,  8.57283058e-19,  7.93356332e-19,\n",
       "       -5.31993030e-20,  2.11931399e-20,  5.73698000e-22, -2.26162843e-21,\n",
       "       -1.31189753e-22, -6.67773114e-22, -1.63642481e-22,  0.00000000e+00,\n",
       "       -1.21523429e-06, -2.62490607e-05, -2.62490607e-05, -1.09371086e-06,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.32820409e-05,\n",
       "        1.09653027e-04,  1.08114274e-04,  3.83955590e-06, -1.96253935e-05,\n",
       "        3.47769209e-06,  4.56395013e-06, -8.52539094e-06, -1.00234796e-04,\n",
       "       -1.14028304e-04,  6.36908903e-05,  2.46993281e-05, -1.35116992e-04,\n",
       "       -8.97867086e-05, -1.72180527e-05, -1.16924325e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  9.65067541e-06,  1.07484127e-04,\n",
       "        2.11224298e-04,  2.77193175e-04,  3.46291486e-04,  2.91238179e-04,\n",
       "        6.32625275e-04,  1.61054475e-03,  2.06415656e-03,  2.35177374e-03,\n",
       "        2.80986400e-03,  2.17816532e-03,  1.76880446e-03,  1.08059298e-03,\n",
       "        4.43768415e-04,  2.56457665e-04,  3.18838283e-05,  1.48969798e-05,\n",
       "       -4.47806855e-06,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -2.56395501e-05,  6.19437888e-05,  2.89773788e-04,\n",
       "        1.81528251e-04,  2.58091626e-04,  5.50547508e-04,  1.07457176e-03,\n",
       "        2.32906993e-03,  4.57459480e-03,  7.82219789e-03,  1.05604091e-02,\n",
       "        1.16136089e-02,  9.80895928e-03,  7.49408807e-03,  4.78645654e-03,\n",
       "        2.80695596e-03,  1.40019686e-03,  6.76689256e-04,  3.34473303e-04,\n",
       "        1.03211664e-04,  2.11782582e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.14019195e-05, -4.76308133e-06,  9.76698176e-05,  3.03431662e-04,\n",
       "        7.04823919e-04,  2.22104418e-03,  4.51876193e-03,  7.88877062e-03,\n",
       "        1.12514504e-02,  1.77495440e-02,  2.38182104e-02,  2.88350374e-02,\n",
       "        3.24026967e-02,  3.08471394e-02,  2.45063525e-02,  1.75648389e-02,\n",
       "        1.01765139e-02,  4.63815959e-03,  2.86703341e-03,  1.67814241e-03,\n",
       "        7.46837993e-04,  1.00162202e-04, -7.03444839e-05, -1.89187100e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  4.71325126e-06,\n",
       "        5.63147991e-05,  1.25942850e-04,  4.92376666e-04,  1.58575750e-03,\n",
       "        3.41626097e-03,  7.44061749e-03,  1.50846827e-02,  2.51795403e-02,\n",
       "        3.54150187e-02,  4.36827856e-02,  5.06565428e-02,  5.36140038e-02,\n",
       "        5.51575493e-02,  5.35325385e-02,  4.66722149e-02,  3.99708198e-02,\n",
       "        2.94351586e-02,  1.69903989e-02,  8.98375357e-03,  5.00309493e-03,\n",
       "        1.93035463e-03,  1.05964453e-04,  1.11274120e-06, -1.36170769e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.39730291e-05,\n",
       "        2.98503384e-04,  5.91417165e-04,  1.12175639e-03,  2.16957110e-03,\n",
       "        6.67313520e-03,  1.71178812e-02,  3.29108387e-02,  4.97894649e-02,\n",
       "        6.31718319e-02,  6.69739925e-02,  6.18608083e-02,  5.41801018e-02,\n",
       "        5.07582526e-02,  5.27632854e-02,  5.82819723e-02,  5.85554310e-02,\n",
       "        5.08668070e-02,  3.44330046e-02,  1.86607689e-02,  7.72450406e-03,\n",
       "        2.06309818e-03,  1.06225040e-04,  1.80536491e-07, -1.08912578e-05,\n",
       "        0.00000000e+00, -1.08179734e-05, -1.69514155e-05, -6.09940894e-05,\n",
       "        1.87559793e-04,  7.76578049e-06,  8.99670682e-04,  4.42147586e-03,\n",
       "        1.24445295e-02,  2.99761120e-02,  5.06513447e-02,  6.83127026e-02,\n",
       "        7.52214843e-02,  6.79031933e-02,  4.81739892e-02,  2.75713011e-02,\n",
       "        1.89041660e-02,  2.84806206e-02,  4.81748645e-02,  6.44028217e-02,\n",
       "        6.59469676e-02,  4.88522610e-02,  2.57649391e-02,  1.01389985e-02,\n",
       "        1.44579666e-03, -6.76222504e-04, -1.00626281e-04,  4.09268205e-05,\n",
       "        0.00000000e+00, -1.18321584e-06, -2.96639406e-05, -5.42020412e-05,\n",
       "       -8.63227588e-05, -5.04584288e-04,  1.68477540e-03,  8.65982239e-03,\n",
       "        2.16170128e-02,  4.39039805e-02,  6.43358664e-02,  7.36669857e-02,\n",
       "        7.00436463e-02,  4.86647719e-02,  1.67934662e-02, -1.05858435e-02,\n",
       "       -1.96884441e-02, -5.43641249e-03,  2.81464699e-02,  5.90832645e-02,\n",
       "        7.30829351e-02,  6.01689707e-02,  3.38270803e-02,  1.21400426e-02,\n",
       "        1.50385390e-03, -1.10716242e-03, -3.83981884e-04, -4.99564824e-05,\n",
       "        0.00000000e+00, -4.52874165e-06,  3.57802507e-05, -1.42939187e-04,\n",
       "        3.62417210e-05,  3.26196760e-04,  5.60295905e-03,  1.66723015e-02,\n",
       "        3.64488479e-02,  5.87380247e-02,  7.39908586e-02,  7.30731017e-02,\n",
       "        5.69460566e-02,  2.81377634e-02, -1.09129372e-02, -4.07481689e-02,\n",
       "       -4.83939108e-02, -2.88547998e-02,  1.14939278e-02,  5.26647381e-02,\n",
       "        7.57699732e-02,  6.83281661e-02,  4.33941074e-02,  1.82191226e-02,\n",
       "        3.51462021e-03, -6.52078377e-04, -2.51378066e-04, -5.95894597e-05,\n",
       "        0.00000000e+00, -1.77973439e-05,  3.56800706e-05, -1.21796770e-04,\n",
       "        6.80457649e-04,  3.34617680e-03,  1.24138516e-02,  2.95890211e-02,\n",
       "        5.41059439e-02,  7.34593610e-02,  7.98588067e-02,  6.91034601e-02,\n",
       "        4.53360686e-02,  9.69061493e-03, -3.15773660e-02, -5.76720275e-02,\n",
       "       -5.93108858e-02, -3.64880102e-02,  7.35718603e-03,  5.45742289e-02,\n",
       "        7.75182663e-02,  7.34813444e-02,  4.94535016e-02,  2.47471590e-02,\n",
       "        6.26877243e-03, -1.24137134e-04, -1.50204447e-04, -6.27994092e-05,\n",
       "        0.00000000e+00, -1.01064176e-05, -1.60905033e-05, -8.44404413e-05,\n",
       "        9.42423150e-04,  6.09214660e-03,  2.09859060e-02,  4.34035207e-02,\n",
       "        7.05976131e-02,  8.34850466e-02,  8.14751368e-02,  6.32299377e-02,\n",
       "        3.33893938e-02, -4.70301235e-03, -4.55915433e-02, -6.47043323e-02,\n",
       "       -5.92522578e-02, -2.91938637e-02,  1.61288358e-02,  5.98530766e-02,\n",
       "        8.03538760e-02,  7.76254699e-02,  5.52696172e-02,  2.97054170e-02,\n",
       "        8.83769837e-03,  1.02217176e-04, -4.16820800e-05,  0.00000000e+00,\n",
       "        0.00000000e+00, -3.70378042e-05,  5.98013731e-06,  1.16306323e-05,\n",
       "        1.49475677e-03,  1.03260902e-02,  2.97810497e-02,  5.84620486e-02,\n",
       "        8.31444542e-02,  8.94668526e-02,  7.77557005e-02,  5.27209254e-02,\n",
       "        2.41402718e-02, -1.60215101e-02, -5.44114420e-02, -6.57680693e-02,\n",
       "       -5.09795426e-02, -1.22545615e-02,  3.40529544e-02,  7.00961277e-02,\n",
       "        8.50725292e-02,  7.91069070e-02,  5.71732730e-02,  3.20163795e-02,\n",
       "        1.05184002e-02,  1.39571587e-04, -3.63827436e-05,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.29584032e-05,  9.47307500e-06,  2.21581330e-04,\n",
       "        2.92371991e-03,  1.62396820e-02,  3.99043120e-02,  7.16461595e-02,\n",
       "        9.08774028e-02,  8.78788661e-02,  6.66431921e-02,  3.98825718e-02,\n",
       "        1.13157805e-02, -3.14062653e-02, -6.51077345e-02, -6.83802574e-02,\n",
       "       -3.67179469e-02,  9.03586937e-03,  5.12215415e-02,  8.06366429e-02,\n",
       "        8.84804086e-02,  7.86672696e-02,  5.67735086e-02,  3.43654967e-02,\n",
       "        1.24686881e-02,  3.69390424e-04, -6.73444267e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.56275621e-05,  2.69487777e-04,\n",
       "        4.71268155e-03,  2.17094016e-02,  4.92908724e-02,  7.95766249e-02,\n",
       "        9.32571351e-02,  8.14296915e-02,  5.24500842e-02,  2.42476810e-02,\n",
       "       -3.53396854e-03, -4.67687085e-02, -7.12857032e-02, -6.61917878e-02,\n",
       "       -2.17095667e-02,  2.11234459e-02,  6.01396424e-02,  8.59484046e-02,\n",
       "        9.17959360e-02,  8.03657186e-02,  5.64682753e-02,  3.29113692e-02,\n",
       "        1.30532224e-02,  6.95121642e-04, -3.88040787e-05,  0.00000000e+00,\n",
       "       -2.63911663e-07,  0.00000000e+00, -9.49789403e-06,  5.61958282e-04,\n",
       "        6.49794372e-03,  2.85026513e-02,  5.87484509e-02,  8.51321172e-02,\n",
       "        9.21333545e-02,  7.40801374e-02,  4.09121715e-02,  1.33259738e-02,\n",
       "       -1.77248367e-02, -5.64995529e-02, -7.28016086e-02, -5.77079668e-02,\n",
       "       -1.36205140e-02,  2.68939476e-02,  6.54669428e-02,  8.89616817e-02,\n",
       "        9.48731987e-02,  8.09287158e-02,  5.55177914e-02,  3.08810378e-02,\n",
       "        1.15983944e-02,  7.70497317e-04, -3.62121716e-05, -4.88750492e-06,\n",
       "       -1.50806665e-06,  0.00000000e+00, -1.73487204e-05,  7.26177901e-04,\n",
       "        8.34725545e-03,  3.47135740e-02,  6.53731013e-02,  8.83873215e-02,\n",
       "        9.07818490e-02,  6.78165851e-02,  3.42623544e-02,  4.09843335e-03,\n",
       "       -2.84544771e-02, -6.02276355e-02, -7.28727051e-02, -4.94703889e-02,\n",
       "       -6.55719033e-03,  3.42782424e-02,  7.19946037e-02,  9.45504481e-02,\n",
       "        9.71110796e-02,  7.92198680e-02,  5.03654215e-02,  2.63281273e-02,\n",
       "        8.54109502e-03,  5.11520047e-04, -3.75377021e-05, -1.08297205e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.19338148e-06,  8.91566369e-04,\n",
       "        1.18337681e-02,  3.98038942e-02,  7.01913484e-02,  9.13238682e-02,\n",
       "        8.95059735e-02,  6.34478201e-02,  2.88307894e-02, -3.77475633e-03,\n",
       "       -3.44868016e-02, -6.17515522e-02, -6.65373944e-02, -3.54364397e-02,\n",
       "        6.62707681e-03,  4.86190400e-02,  8.36538146e-02,  1.00937607e-01,\n",
       "        9.61565419e-02,  7.07201898e-02,  4.23574138e-02,  1.98090119e-02,\n",
       "        5.44271113e-03,  4.54445480e-04, -1.16910757e-04, -1.16407096e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.03324685e-04,  1.20811283e-03,\n",
       "        1.38574344e-02,  4.24271285e-02,  7.20952061e-02,  9.18579712e-02,\n",
       "        8.73361682e-02,  6.08366572e-02,  2.58066138e-02, -6.40257902e-03,\n",
       "       -3.53790920e-02, -5.39464787e-02, -4.76111550e-02, -1.35659605e-02,\n",
       "        2.97733342e-02,  7.15687022e-02,  9.81900441e-02,  1.04064206e-01,\n",
       "        8.69745310e-02,  5.94511681e-02,  3.35712572e-02,  1.42418791e-02,\n",
       "        4.01428513e-03,  5.85935966e-04, -1.07127638e-04, -8.29967651e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.56469272e-04,  1.59370095e-03,\n",
       "        1.36488548e-02,  4.27140183e-02,  7.08603137e-02,  8.91623149e-02,\n",
       "        8.42531548e-02,  6.24760388e-02,  3.08465619e-02,  9.96792739e-04,\n",
       "       -2.10430458e-02, -3.13336298e-02, -1.91537096e-02,  1.71695265e-02,\n",
       "        5.81314464e-02,  9.12835328e-02,  1.04233568e-01,  9.62130847e-02,\n",
       "        7.03976796e-02,  4.47669372e-02,  2.27543966e-02,  8.65739230e-03,\n",
       "        2.44011836e-03,  3.53704253e-04, -7.33729740e-05, -6.45084856e-05,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.88173305e-04,  1.43598724e-03,\n",
       "        1.21275829e-02,  3.68034285e-02,  6.40293215e-02,  8.48354032e-02,\n",
       "        8.90492146e-02,  7.42052482e-02,  5.04257677e-02,  2.56767041e-02,\n",
       "        8.56097083e-03,  4.26767968e-03,  1.81771252e-02,  4.70391995e-02,\n",
       "        7.65779896e-02,  9.41097388e-02,  9.23736176e-02,  7.41693279e-02,\n",
       "        4.95688786e-02,  2.77480191e-02,  1.30098542e-02,  4.15123858e-03,\n",
       "        5.37917694e-04,  1.34877768e-04, -6.89913046e-05,  0.00000000e+00,\n",
       "       -1.86382908e-05, -5.82446586e-06,  1.98109530e-04,  9.87854076e-04,\n",
       "        8.27121314e-03,  2.50120980e-02,  4.96699007e-02,  7.19120224e-02,\n",
       "        8.16836312e-02,  7.96165911e-02,  6.60528545e-02,  4.99781289e-02,\n",
       "        4.00159878e-02,  3.56403344e-02,  4.27965053e-02,  5.92154780e-02,\n",
       "        7.37937125e-02,  7.75765559e-02,  6.53696342e-02,  4.45987416e-02,\n",
       "        2.70384887e-02,  1.35590833e-02,  5.93259224e-03,  1.50658445e-03,\n",
       "        8.45610325e-05,  1.25582487e-05,  1.52271429e-05,  0.00000000e+00,\n",
       "       -1.80558442e-05, -5.82446586e-06,  6.35758912e-05,  4.61951850e-04,\n",
       "        3.43449463e-03,  1.28397962e-02,  2.88458257e-02,  4.81085917e-02,\n",
       "        5.98171658e-02,  6.42384727e-02,  5.83337371e-02,  4.98777452e-02,\n",
       "        4.30431115e-02,  3.83309927e-02,  3.92632720e-02,  4.49054222e-02,\n",
       "        4.80592953e-02,  4.58475336e-02,  3.37055849e-02,  2.10730059e-02,\n",
       "        1.12819591e-02,  4.64531546e-03,  1.57612212e-03,  4.58147067e-04,\n",
       "       -1.03196794e-04, -4.01925506e-05,  1.56980855e-06,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.58693842e-05,  1.94583511e-04,\n",
       "        5.76018850e-04,  2.73670661e-03,  8.65413799e-03,  1.75435011e-02,\n",
       "        2.52008489e-02,  3.07675222e-02,  3.18822496e-02,  2.75049209e-02,\n",
       "        2.07913959e-02,  1.60159779e-02,  1.43353292e-02,  1.32770716e-02,\n",
       "        1.57857903e-02,  1.62521731e-02,  1.15715295e-02,  7.04156711e-03,\n",
       "        3.64228964e-03,  1.57893864e-03,  5.58756021e-04,  2.21118684e-04,\n",
       "       -4.90289763e-05, -1.45880661e-06,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.20293705e-05,\n",
       "       -9.63126109e-05,  9.23675414e-05,  3.01360171e-05, -1.11724270e-04,\n",
       "        1.43834516e-04,  3.29094271e-04, -2.17625182e-03, -3.94217246e-03,\n",
       "       -5.93378315e-03, -6.23210242e-03, -5.84374459e-03, -4.75604540e-03,\n",
       "       -2.26478821e-03,  1.55777168e-04,  1.89941792e-03,  2.19655511e-03,\n",
       "        1.30446208e-03,  5.73890032e-04,  4.99048988e-04, -1.49831185e-05,\n",
       "       -8.35328860e-05, -3.86583750e-05, -1.78703809e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -6.71173576e-05, -2.99428891e-04, -5.83463816e-04, -1.26586828e-03,\n",
       "       -2.55727023e-03, -4.39014669e-03, -7.37609492e-03, -9.71006937e-03,\n",
       "       -1.05740249e-02, -1.01572698e-02, -8.95841922e-03, -6.46936105e-03,\n",
       "       -3.18067062e-03, -1.21421345e-03,  6.65490297e-05,  4.40527583e-04,\n",
       "        5.57540925e-04,  2.39705739e-04,  1.21743736e-04, -3.99385207e-08,\n",
       "       -4.65732341e-06, -1.58645218e-05, -1.89644859e-05,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.75021523e-06, -5.50810674e-05, -1.97941509e-04, -4.77004126e-04,\n",
       "       -1.16857244e-03, -1.78839665e-03, -2.67268632e-03, -4.49675379e-03,\n",
       "       -4.98634658e-03, -4.89750258e-03, -4.14579652e-03, -2.72757792e-03,\n",
       "       -1.30353328e-03, -2.45682789e-04,  1.16276592e-04,  2.27721072e-04,\n",
       "        3.26862157e-04,  1.25651197e-04,  3.90104125e-05,  7.78167466e-07,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -3.40004062e-05, -3.00974404e-05,\n",
       "        1.37164190e-05, -9.52614323e-05, -8.56725804e-05, -8.63627951e-05,\n",
       "       -1.33590100e-04, -1.43292840e-04, -1.50556153e-04, -1.48353126e-04,\n",
       "       -7.89651509e-05,  8.07926760e-06, -9.22127856e-06,  3.87555866e-06,\n",
       "        7.48479864e-07,  4.82649812e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.T[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 설명된 분산의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exlaned_variance_ratio: 변수에 저장된 주성분의 설명된 분산의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09818467, 0.06988009])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 적절한 차원 수 선택하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 축소할 차원 수를 임의로 정하기보다는 충분한 분산이 될 때까지 더해야 할 차원 수를 선택하는 쪽을 선호합니다. 물론 데이터 시각화를 위해 차원을 축소하는 경우에는 2, 3개로 줄이는 것이 일반적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원을 축소하지 않고 PCA를 계산한 뒤 훈련 세트의 분산을 95%로 유지하는 데 필요한 최소한 차원의 수를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그런 다음 n_components=d로 설정하여 PCA를 다시 실행한다. 하지만 유지하려는 주성분의 수를 지정하기 보다는 보존하려는 분산의 비율을 n_componetns에 0.0에서 1.0 사이로 설정하는 편이 낫다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 압축을 위한 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원을 축소하고 난 후에는 훈련 세트의 크기가 줄어든다. 예를 들어 MNIST 데이터 셋에 분산의 95%를 유지하도록 PCA를 적용해보겠다. 각 샘플은 원래의 784개 특성이 아니라 150개 정도만 가지고 있을 것이다. 대부의 분산은 유지되었지만 데이터셋은 원본 크기의 20% 미만이 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 또한 압축된 데이터셋에 PCA 투영의 변환을 적용하여 784개 차원으로 되돌릴 수도 있다. 물론 투영에서 일정량의 정보를 잃었기 때문에 원본 데이터셋을 얻을 수는 없다. 하지만 원본 데이터와 매우 비슷할 것이다. 원본 데이터와 재구성된 데이터 사이의 평균 제곱 거리를 재구성 오차라 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예를 들어 다음 코드는 MNIST를 154차원으로 압축하고 inverse_transform() 메서드를 사용해 784차원으로 복원한다. 원본 훈련 세트와 샘플을 압축한 후 복원한 결과를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=154)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xreccov = Xd-proj * Wd(Transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 점진적 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA 구현의 문제는 SVD 알고리즘을 실행하기 위해 전체 훈련 세트를 메모리에 올려야 한다는 것이다. 다행히 점진적 PCA 알고리즘(IPCA)이 개발되었다. 훈련 세트를 미니배치로 나눈 뒤 IPCA 알고리즘에 한 번에 하나씩 주입한다. 이런 방식은 훈련 세트가 클 때 유용하고 온라인으로 PCA를 적용할 수 있다.\n",
    "\n",
    "- 다음 코드는 MNIST 데이터셋을 100개의 미니배치로 나누고 사이킷런의 IncrementalPCA 파이썬 클래스에 주입하여 MNIST 데이터 셋을 이전과 같이 154개로 줄인다. 전체 훈련 세트를 사용하는 fit() 메서드가 아니라 partial_fit() 메서드를 미니배치마다 호출해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=149)\n",
    "\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "    \n",
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 또 다른 넘파이의 memmap 파이썬 클래스를 사용해 하드 디스크의 이진 파일에 저장된 매우 큰 배열을 메모리에 들어 있는 것처럼 다루는 것이다. 이 파이썬 클래스는 필요할 때 이진 파일에 저장된 매우 큰 배열을 메모리에 들어있는 것처럼 다루는 것이다. 이 파이썬 클래스는 필요할 때 데이터를 메모리에 적재한다. IncrementalPCA는 특정 순간에 배열의 일부만 사용하기 때문에 메모리 부족 문제를 해결할 수 있다. 다음 코드처럼 이 방식을 젖아하면 일반적인 fit() 메서드를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_mm = np.memmap(filename, dtype=\"float32\", mode='read')\n",
    "\n",
    "#batch_size = m // n_batches\n",
    "#inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "#inc_pca.fit(X_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 랜덤 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런에서는 PCA의 또 다른 옵션으로 랜덤 PCA를 찾습니다. 이 방식은 확률적인 알고리즘으로, 첫 d개의 주성분에 대한 근사값을 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver='randomized')\n",
    "X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 커널 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM에서 샘플을 매우 높은 고차원 공간(특성 공간)으로 암묵적으로 매핑하여 서포트 벡터 머신의 비선형 분류와 회귀를 가능하게 하는 수학적 기법인 커널 트릭에 대해 이야기했습니다. 고차원 특성 공간에서의 선형 결정 경계는 원본 공간에서는 복잡한 비선형 결정 경계에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 같은 기법을 PCA에 적용해 복잡한 비선형 투영으로의 차원 축소를 가능하게 할 수 있다. 이를 커널 PCA라고 합니다. 이 기법은 투영된 후에 샘플의 군집을 유지하거나 꼬인 매니폴드에 가까운 데이터셋을 펼칠 떄도 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예를 들어, 다음 코드는 사이킷런의 KernelPCA를 사용해 RBF 커널로 kPCA를 적용하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 커널 선택과 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kPCA는 비지도 학습이기 때문에 좋은 커널과 하이퍼파리미터를 선택하기 위한 명확한 성능 측정 기준이 없다. 하지만 차원 축소는 종종 지도 학습의 전처리 단계로 활용되므로 그리드 탐색을 사용하여 주어진 문제에서 성능이 가장 좋은 커널과 하이퍼파라미터를 선택할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 코드는 두 단계의 파이프라인을 만드는데, 먼저 kPCA를 사용해 사용해 차원을 2차원으로 축소하고 분류를 위해 로지스틱 호귀를 적용합니다. 그런 다음 파이프라인 마지막 단계에서 가장 높은 분류 정확도를 얻기 위해 GridSearchCV를 사용해 kPCA 가장 좋은 커널과 gamma 파라미터를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('kpca', KernelPCA(n_components=2)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid = [{\n",
    "    'kpca__gamma': np.linspace(0.03, 0.05, 10),\n",
    "    'kpca__kernel': ['rbf', 'sigmoid']\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "\n",
    "# grid_search.fit(X, y)\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 커널 트릭 덕분에 훈련 세트를 특성 맵을 사용한 무한 차원의 특성 공간게 매핑한 다음, 변환된 데이터셋을 선형 PCA를 사용해 2D로 투영한 것과 수학적으로 동일합니다. 축소된 공간에 있는 샘플에 대해 선형 PCA를 역전시키면 재구성된 포인트는 원본 공간이 아닌 특성 공간에 놓게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 특성 공간은 무한 차원이기 떄문에 재구성된 포인트를 계산할 수 없고 재구성에 따른 실제 에러를 계산할 수 없다. 다행히 재구성된 포인트에 가깝게 매핑된 원본 공간의 포인트를 찾을 수 있다. 이를 재구성 원상이라 부릅니다. 원상을 얻게 되면 원본 샘플과의 거리를 측정할 수 있다. 그래서 재구성 원상의 오차를 최소화 하는 커널을 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.04333, fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4367.994644967508"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지역 선형 임베딩은 또 다른 강력한 비선형 차원 축소 기술이다. 이전 알고리즘처럼 투영에 의존하지 않는 매니폴드를 학습합니다. 간단히 말해 LLE는 먼저 각 훈련 샘플이 가장 가까운 이웃에 얼마나 선형적으로 연관되어 있는지 측정합니다. 그런 다음 국부적인 관계가 가장 잘 보존된느 세트의 저차원 표현을 찾습니다. 이는 특히 잡음이 너무 많지 않은 꼬인 매니폴드를 펼치는데 잘 작동한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 다른 차원 축소 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다차원 스케일링: 샘플 간의 거리를 보존하면서 차원을 축소한다.\n",
    "\n",
    "- Isomap: 각 샘플을 가장 가까운 이웃을 연결하는 식으로 그래프를 만든다. 그런 다음 샘플 간의 지오데식 거리를 유지하면서 거리를 축소한다.\n",
    "\n",
    "- tSNE: 비슷한 샘플은 가까이 비슷하지 않은 샘플은 멀리 떨어지도록 하면서 차원을 축소한다. 주로 시각화에 많이 이용되며 특히 고차원 공간에 있는 샘플의 군집을 시각화할 떄 사용한다.\n",
    "\n",
    "- 선형 판별 분석(Linear Discriminant Analysis)는 사실 분류 알고리즘입니다. 하지만 훈련 과정에서 클래스를 가장 잘 구분하는 축을 학습한다. 이 축은 데이터가 투영되는 초평면을 정의하는데 사용할 수 있다. 이 알고리즘의 장점은 투영을 통해 가능한 클래스를 멀리 떨어지게 유지시키므로 SVM 분류기 같은 분류 알고리즘을 적용하기 전에 차원을 축소시키는 데 좋다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
